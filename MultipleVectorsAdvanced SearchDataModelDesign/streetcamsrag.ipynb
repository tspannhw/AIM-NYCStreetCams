{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7eda13-5c3f-4394-9b42-0756129f7f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothyspann/Downloads/code/milvusvenv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pymilvus import MilvusClient\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain import hub\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain import hub\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import requests\n",
    "import sys\n",
    "import io\n",
    "import json\n",
    "import shutil\n",
    "import sys\n",
    "import datetime\n",
    "import subprocess\n",
    "import math\n",
    "import base64\n",
    "from time import gmtime, strftime\n",
    "import random, string\n",
    "import time\n",
    "import psutil\n",
    "import base64\n",
    "import uuid\n",
    "import socket\n",
    "from pymilvus import connections\n",
    "from pymilvus import utility\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType, Collection\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "from sklearn.preprocessing import normalize\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from IPython.display import display\n",
    "from pymilvus import MilvusClient\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from langchain_milvus import Milvus\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)\n",
    "from langchain_core.globals import set_verbose, set_debug\n",
    "\n",
    "# Disable verbose logging\n",
    "set_verbose(False)\n",
    "\n",
    "# Disable debug logging\n",
    "set_debug(False)\n",
    "\n",
    "### Setup environment and constants\n",
    "\n",
    "DIMENSION = 384 \n",
    "MILVUS_URL = \"http://192.168.1.153:19530\" \n",
    "\n",
    "slack_token = os.environ.get(\"SLACK_BOT_TOKEN\")\n",
    "client = WebClient(token=slack_token)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "SC_COLLECTION_NAME = \"nycstreetcameras\"\n",
    "DEFAULT_QUERY = \"What is the current weather in detail from Central park.\"\n",
    "\n",
    "### Environment Variables needed\n",
    "os.environ[\"LANGCHAIN_HUB_API_URL\"] = \"https://api.hub.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_HUB_API_KEY\"] = os.environ.get(\"LANGCHAIN_HUB_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.environ.get(\"LANGCHAIN_HUB_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.hub.langchain.com\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]  = \"true\"\n",
    "\n",
    "### Turn off slack warnings\n",
    "os.environ[\"SKIP_SLACK_SDK_WARNING\"] = \"false\"\n",
    "\n",
    "# https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.milvus.Milvus.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1af4f4-db02-4af0-8637-e5c53bc1afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up connection to Milvus for NYC Street Cameras, weather text vector\n",
    "vector_store = Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=SC_COLLECTION_NAME,\n",
    "    primary_field = \"id\",\n",
    "    vector_field = \"weather_text_vector\",\n",
    "    text_field=\"weatherdetails\",\n",
    "    connection_args={\"uri\": MILVUS_URL},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "260235a1-c578-4871-9878-6cb6d6eaeb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Location query:  Central Park\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A formatted weather report!\n",
      "\n",
      "Here's the detailed weather report for New York City, Central Park [KNYC] in NY @ 40.666723,-73.995808 on August 28th at 08:51 am EDT:\n",
      "\n",
      "**Current Weather Condition:** Fair\n",
      "\n",
      "**Temperature:** 76째F (24째C)\n",
      "\n",
      "**Dew Point:** 66째F (19째C)\n",
      "\n",
      "**Relative Humidity:** 72%\n",
      "\n",
      "**Wind Speed:** Not Available (NA)\n",
      "\n",
      "**Visibility:** 9.00 miles (14.48 km) at an elevation of 30 meters (98 ft)\n",
      "\n",
      "**Altimeter Reading:** 1014.7 millibars (mb)\n",
      "\n",
      "This weather report is based on the provided data, which appears to be a combination of meteorological and observational data from a specific location.\n",
      "\n",
      "Please note that this report may not reflect the actual current weather conditions in New York City, Central Park [KNYC] as it is generated from a hypothetical dataset."
     ]
    }
   ],
   "source": [
    "# https://zilliz.com/blog/building-multilingual-rag-milvus-langchain-openai\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "retriever = vector_store.as_retriever(collection =  SC_COLLECTION_NAME)\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"llama3\",\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "    stop=[\"<|eot_id|>\"],\n",
    ")\n",
    "\n",
    "template=\"\"\"\n",
    "   Use the context to build detailed weather reports for the location asked for and format in Slack mrkdwn format.\n",
    "   {location}\n",
    "   Context: {context}\n",
    "   Answer:\"\"\"\n",
    "  \n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "      {\"context\": retriever, \"location\": RunnablePassthrough()}\n",
    "      | prompt\n",
    "      | llm\n",
    "      | StrOutputParser()\n",
    "  )\n",
    "\n",
    "query = input(\"Location query: \")\n",
    "\n",
    "response = chain.invoke(query)\n",
    "\n",
    "try:\n",
    "    slackresponse =  str(response).replace(\"**\",\"*\")\n",
    "                               \n",
    "    slackresponse = client.chat_postMessage(mrkdwn=True, channel=\"C06NE1FU6SE\", text=\"\", \n",
    "                                        blocks=[{\"type\": \"section\",\"text\": {\"type\": \"mrkdwn\",\"text\": str(slackresponse) +\"\\n\" }}])\n",
    "\n",
    "    # print(\"\\n\\nSLACKREPONSE: \\n\" + str(slackresponse))   \n",
    "    # could save this or send to mqtt or kafka or pulsar or store to minio/s3 or milvus\n",
    "except SlackApiError as e:\n",
    "    # You will get a SlackApiError if \"ok\" is False\n",
    "    print(\"Slack failed\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802515c-d927-483f-88b3-d4a2b44173bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
